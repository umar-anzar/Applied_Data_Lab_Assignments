{"cells":[{"cell_type":"markdown","metadata":{"id":"8c341bc7"},"source":["# Applied Data Lab\n","\n","# Assignment 02: Pandas"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1696934376825,"user":{"displayName":"Muhammad Umar Anzar","userId":"10020185523127189936"},"user_tz":-300},"id":"VY9srXeg_1Sp"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"ZdR7SqgGt1Pm"},"source":["## Setting Up the Address\n","In this cell, a path variable is set with the value of the current directory where the notebook is open. This is done to easily upload the dataset file from this location."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7UvjMzSaPW3"},"outputs":[],"source":["# Run this cell\n","import os\n","PATH = os.getcwd() + '/'\n","PATH"]},{"cell_type":"markdown","metadata":{"id":"hio8vNa6Z7Rw"},"source":["**ONLY FOR GOOGLE COLAB USERS**\n","\n","For those who are using **Google Colab**, uncomment and run the cell below.\n","\n","**Note**: You have to repalce value of variable `YOUR_PATH_TO_DATASET_DIRECTORY` with the path where your dataset is placed in the Google Drive folder.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1q0rU2XaGy0"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n","# YOUR_PATH_TO_DATASET_DIRECTORY = \"work/Applied_Data_Lab/phase_2\"\n","# PATH = \"/content/drive/MyDrive/\"+YOUR_PATH_TO_DATASET_DIRECTORY+\"/\"\n","# PATH"]},{"cell_type":"markdown","metadata":{"id":"YkpL40Yw-2uy"},"source":["### Exercise 1: Read Data\n","\n","Import the `Corporate_Financial_Metrics_Dataset.csv` in variable `data`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqxQweL27q4L"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":400,"status":"ok","timestamp":1696948669278,"user":{"displayName":"Muhammad Umar Anzar","userId":"10020185523127189936"},"user_tz":-300},"id":"KiJuqA39_9wI"},"outputs":[],"source":["#HINT\n","# data = pd.read_csv(PATH+'Corporate_Financial_Metrics_Dataset.csv')"]},{"cell_type":"markdown","metadata":{"id":"G8dfD3FkHbpN"},"source":["## Selecting Columns in Pandas\n","\n","You can select columns in Pandas using multiple methods. The primary methods are:\n","\n","1. Using **Double Square Brackets `[[]]`** to return a DataFrame with one or more columns:\n","   \n","   ```python\n","   # Selecting a single column, returns a DataFrame\n","   df[['Column1']]\n","   \n","   # Selecting multiple columns, returns a DataFrame\n","   df[['Column1', 'Column2']]\n","   ```\n","\n","2. Using **Single Square Brackets `[]`** with the column name(s) inside, which returns a Series if selecting a single column and a DataFrame if selecting multiple columns:\n","   \n","   ```python\n","   # Selecting a single column, returns a Series\n","   df['Column1']\n","   \n","   # Selecting multiple columns, returns a DataFrame\n","   df[['Column1', 'Column2']]\n","   ```\n","\n","3. Using **`.loc[]`** with row and column selectors to return specific rows and columns as a DataFrame:\n","   \n","   ```python\n","   # Using .loc[] to select specific rows and columns\n","   df.loc[:, 'Column1']\n","   df.loc[:, ['Column1', 'Column2']]\n","   ```\n","\n","Remember that the first two methods, using single and double square brackets, are most commonly used for column selection.\n"]},{"cell_type":"markdown","metadata":{"id":"RqbjRdWFahuA"},"source":["### Exercise 2: Selecting `sector` Column\n","\n","select single sector column and display it\n","using any method .loc or simple []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4g7AwT3QHlad"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"C0xRUOnIcT7u"},"source":["### Exercise 3: Calculate Frequency of Sector Values\n","\n","**Objective:** Calculate and display the frequency of sector values in a DataFrame.\n","\n","**Instructions:**\n","\n","\n","1. Calculate the frequency of sector values without using Pandas. Use the provided code to create a dictionary (`freq`) and loop through the 'Sector' column to count the frequency of each sector value.\n","\n","   ```python\n","   freq = {}\n","   for sector in df.loc[:,'column']:\n","       if sector not in freq:\n","           freq[sector] = 0\n","       freq[sector] += 1\n","\n","   print(freq)\n","   ```\n","\n","2. Calculate the frequency of sector values using Pandas' `value_counts()` method and display the result in a pandas Series.\n","\n","**Hint**: `df.value_counts()` or `series.value_counts()`\n","\n","\n","3. Print the frequency of sector values calculated using both methods. Compare the results.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsQf6kFycTPe"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"FPNiGVcKdaw-"},"source":["### Exercise 4: Normalize Frequency Result\n","\n","**Objective:** Normalize the frequency values of sectors in the DataFrame and display the normalized results.\n","\n","**Instructions:**\n","\n","1. Use `value_counts()` method to calculate the frequency of sector values from the 'Sector' column and save the result in a variable called `sector_freq`.\n","\n","2. Divide the `sector_freq` Series by the total number of rows in the DataFrame (`len(data)`).\n","\n","**Hint**: `sector_freq / len(data)`\n","\n","3. Print the normalized frequency values.\n","\n","By normalizing the frequency values, you'll get a sense of the proportion of each sector within the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fvjuf6FOdsUu"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"1TUJ6eI3U1oz"},"source":["### Exercise 5: Normalize Frequency Result Using the 'normalize' Argument\n","\n","**Objective:** Normalize the frequency values of sectors in the DataFrame using the `normalize` argument in the `value_counts()` method and display the normalized results.\n","\n","**Instructions:**\n","\n","1. Use Pandas' `value_counts()` method on the 'Sector' column of the DataFrame. Pass the argument `normalize=True` to the method. This will calculate and return the normalized frequency values directly.\n","\n","**Hint**: `value_counts(normalize=True)`\n","\n","2. Print the `sector_freq_normalized` Series to display the normalized frequency values.\n","\n","Using the `normalize=True` argument simplifies the process of obtaining normalized frequency values from the 'Sector' column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGztFDrwetym"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"R5u7At5Xdrgr"},"source":["## Selecting Rows Using Boolean Mask/Indexing\n","\n","You can select specific rows from a DataFrame using a boolean mask or indexing. A boolean mask is essentially a series with the same length as the DataFrame, containing `True` and `False` values. When you apply this mask to the DataFrame, it selects rows where the mask is `True`.\n","\n","Here's an example to illustrate how this works:\n","\n","```python\n","# Import Pandas\n","import pandas as pd\n","\n","# Sample DataFrame\n","person = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n","        'Age': [25, 30, 22, 35]}\n","df = pd.DataFrame(person)\n","\n","# Create a boolean mask to select rows where 'Age' is greater than 25\n","mask = [True, False, False, True]\n","\n","# Apply the mask to the DataFrame\n","selected_rows = df[mask]\n","\n","print(selected_rows)\n","```\n","\n","In this example, we've created a boolean mask (`mask`) where `True` values indicate the rows to select (in this case, the first and last rows). When the mask is applied to the DataFrame, it filters the rows accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_iLcFUifAOq"},"outputs":[],"source":["# Run this cell\n","person = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n","        'Age': [25, 30, 22, 35]}\n","df = pd.DataFrame(person)\n","print(\"Data\")\n","display ( df )\n","\n","mask = [True, False, False, True]\n","selected_rows = df[mask]\n","selected_rows\n","print(\"\\n\\nSelected Data\")\n","display ( selected_rows )"]},{"cell_type":"markdown","metadata":{"id":"9Qy10Uj0euV9"},"source":["## Comparison Operators\n","\n","Comparison Operators in Pandas are used to filter rows in a DataFrame based on certain conditions. These operators are similar to the ones used in Python. Here's a summary of common comparison operators and their descriptions:\n","\n","| Operator | Description                  |\n","|----------|------------------------------|\n","| `<`      | Less than                    |\n","| `>`      | Greater than                 |\n","| `<=`     | Less than or equal to       |\n","| `>=`     | Greater than or equal to    |\n","| `!=`     | Not equal to                 |\n","| `==`     | Equal to                     |\n","\n","You can use these operators to create conditions and filter rows in a DataFrame accordingly. For example, you can filter rows where a particular column is greater than a specific value or where two columns are not equal.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WG1kxus6gJsa"},"outputs":[],"source":["# Run this cell\n","df['Age'] > 25"]},{"cell_type":"markdown","metadata":{"id":"x5oVbPpvgRli"},"source":["This returns a boolean mask for records where the age is greater than 25. You can use this mask and pass it to the DataFrame (`df`) to retrieve the corresponding records.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2X45Ip4gk6q"},"outputs":[],"source":["# Run this cell\n","mask = df['Age'] > 25\n","df[mask]"]},{"cell_type":"markdown","metadata":{"id":"V-mHIM7mg9If"},"source":["Alternate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_x8RM5VgmMQ"},"outputs":[],"source":["# Run this cell\n","df[ df['Age'] > 25 ]"]},{"cell_type":"markdown","metadata":{"id":"7aTnDi0IggJk"},"source":["### Exercise 6: Selecting Records with Revenues Greater Than Median\n","\n","**Objective:** Calculate the median of revenues and select records with revenues greater than the median.\n","\n","**Instructions:**\n","\n","1. Calculate the median of the 'revenues' column using the `median()` method and save it in a variable named `median_revenues`.\n","\n","**Hint:** `data['col'].meadian()`\n","\n","2. Apply a filter to the DataFrame to select records with revenues greater than the median.\n","\n","**Hint:** `data[ data['col'] > x ]`\n","\n","3. Print the `selected_records` DataFrame to display the records with revenues greater than the median."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoggRq69haz0"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"lCqLxQ78wGyl"},"source":["### Exercise 7: Selecting Records with Revenues Equal & Less Than Mean\n","\n","**Objective:** Calculate the mean of revenues and select records with revenues equal and less than the mean.\n","\n","**Instructions:**\n","\n","1. Calculate the mean of the 'revenues' column using the `mean()` method and save it in a variable named `mean_revenues`.\n","\n","2. Apply a filter to the DataFrame to select records with revenues equal and less than the median.\n","\n","3. Print the `selected_records` DataFrame to display the records with revenues greater than the median."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fI5qROXGwGFk"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"58vFm7uW4zLY"},"source":["## Logical Operators in Pandas\n","\n","Pandas also supports logical operators that allow you to create complex conditions for filtering rows in a DataFrame. Here are the common logical operators and their descriptions:\n","\n","- `&` (AND): Combines two or more conditions and returns `True` if all conditions are `True`.\n","- `|` (OR): Combines two or more conditions and returns `True` if at least one condition is `True`.\n","- `~` (NOT): Negates a condition, returning `True` if the condition is `False`.\n","\n","You can use these logical operators to create compound conditions for row selection in a DataFrame. For example, you can filter rows where a specific column meets multiple conditions, or you can exclude rows based on a particular condition.\n","\n","Here's an example of using logical operators in Pandas:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r28Z5XG6BI0-"},"outputs":[],"source":["# Run this cell\n","\n","person = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n","        'Age': [25, 30, 22, 35],\n","        'Salary': [50000, 60000, 45000, 70000]}\n","df = pd.DataFrame(person)\n","\n","# Create a condition to filter rows where 'Age' is greater than 25 and 'Salary' is less than 60000\n","condition = (df['Age'] > 25) & (df['Salary'] < 70000)\n","\n","# Apply the condition to select rows\n","selected_rows = df[condition]\n","\n","print(selected_rows)"]},{"cell_type":"markdown","metadata":{"id":"NyJ2jFChBldn"},"source":["In this example, the logical operators `&` are used to create a compound condition, and the resulting DataFrame `selected_rows` contains rows that satisfy both conditions.\n","\n","Using logical operators allows you to perform advanced row filtering based on multiple criteria in your DataFrame."]},{"cell_type":"markdown","metadata":{"id":"YV7v9uzABmTV"},"source":["### Exercise 8: Select Records Based on Two Constraints\n","\n","**Objective:** Select records from the DataFrame where the headquarters location is `'Beijing, China'` and revenues are greater than the mean of revenues.\n","\n","**Instructions:**\n","\n","1. Calculate the mean of revenues using the `mean()` method on the 'Revenues' column. Store the result in a variable named `mean_revenues`.\n","\n","2. Create a condition to filter rows where 'HQ_Location' is equal to `'Beijing, China'` and 'Revenues' are greater than `mean_revenues`. You can use logical operators (`&` **AND gate**) to combine these conditions.\n","\n","3. Apply the condition to select rows that meet both constraints and store the result in a new DataFrame called `selected_records`.\n","\n","4. Print the `selected_records` DataFrame to display the records that satisfy both constraints."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knVccc-oDUO0"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"UPJzkAhWkK1i"},"source":["### Exercise 9: Sort Data by Single Column\n","\n","**Objective:** Sort the data by the 'Total_Stockholder_Equity' column in ascending order.\n","\n","**Instructions:**\n","\n","1. Use the `sort_values()` method on the DataFrame to sort the data by the 'Total_Stockholder_Equity' column in ascending order (`ascending=True`).\n","\n","**Hint:** `data.sort_values(by='column_name', ascending=True/False)`\n","\n","2. Save the sorted DataFrame in a variable named `sorted_data`.\n","\n","3. Print the `sorted_data` DataFrame to display the data sorted by total stockholder equity in ascending order."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UzPHhJ2bkrcL"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]},{"cell_type":"markdown","metadata":{"id":"0AfzR3_lk7J0"},"source":["### Exercise 10: Select Records Having Maximum Total Stockholder Equity for Each Country\n","\n","**Objective:** Select records for each country where the total stockholder equity is maximum within that country.\n","\n","**Instructions:**\n","\n","In this exercise, you will use the `groupby` method in pandas to group the data by the 'country' column and then filter records where the total stockholder equity is maximum within each country. Here are the steps:\n","\n","1. **Group Data by Country:**\n","   - Use the `groupby` method to group the data by the 'country' column.\n","   - Apply the `['total_stockholder_equity']` indexer to select the 'total_stockholder_equity' column for each group.\n","\n","   ```python\n","   max_group_equity = data.groupby('country')['total_stockholder_equity']\n","   ```\n","\n","2. **Find the Maximum Equity in Each Group:**\n","   - Use the `transform` method to find the maximum total stockholder equity within each group (country).\n","\n","   ```python\n","   max_equity_by_country = max_group_equity.transform('max')\n","   ```\n","\n","3. **Filter Records with Maximum Equity:**\n","   - Create a boolean mask by comparing the 'total_stockholder_equity' column with the 'max_equity_by_country' series.\n","   - Use this mask to filter the records where the total stockholder equity is maximum within each country.\n","\n","   ```python\n","   filtered_data = data[data['total_stockholder_equity'] == max_equity_by_country]\n","   ```\n","\n","4. **Result:**\n","   - The `filtered_data` DataFrame will contain records with the maximum total stockholder equity for each country.\n","\n","   ```python\n","   filtered_data[['country','company']]\n","   ```\n","\n","By following these steps, you can easily select records with the greatest total stockholder equity within each country in the dataset.\n","\n","\n","**Note:** We won't delve into a detailed explanation of the `groupby` and `transform` methods at this point, as they are more advanced topics. However, you can use these methods to efficiently group and perform calculations on data within specific groups in a pandas DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-QHLr6Vk6qU"},"outputs":[],"source":["# Do Exercise in this cell\n","#\n","#\n","#"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMfniXGOr8Lk1/FAJdcrszo","provenance":[{"file_id":"1puZ9Wctrv7XcSQylFcucpFvSDrfFWSTX","timestamp":1696866822630}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
